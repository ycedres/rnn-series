{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NREL - Offshore WA OR - turbine: 25915\n",
    "\n",
    "## Predicci√≥n: h = 12 / H = 24\n",
    "\n",
    "## Model: Neural Network - Stack LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# import RenewAI\n",
    "sys.path.append('/Users/tmorales/tmp/RNN-windPower/src')\n",
    "from pre_process.split_ml_ts import dataframe_split\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics.regression import mean_squared_error\n",
    "from sklearn.metrics.regression import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_path = '/Users/tmorales/tmp/experiments/NREL/Offshore_WA_OR/turbine_25915/lag_5_h_12'\n",
    "experiment_name = 'nn-stack-lstm'\n",
    "directory = os.path.join(exp_path, experiment_name)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/tmorales/tmp/RNN-windPower/database/wind_farms/Offshore_WA_OR/Offshore_WA_OR_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Offshore_WA_OR_features_h_01.csv',\n",
       " 'Offshore_WA_OR_features_h_02.csv',\n",
       " 'Offshore_WA_OR_features_h_03.csv',\n",
       " 'Offshore_WA_OR_features_h_04.csv',\n",
       " 'Offshore_WA_OR_features_h_05.csv',\n",
       " 'Offshore_WA_OR_features_h_06.csv',\n",
       " 'Offshore_WA_OR_features_h_07.csv',\n",
       " 'Offshore_WA_OR_features_h_08.csv',\n",
       " 'Offshore_WA_OR_features_h_09.csv',\n",
       " 'Offshore_WA_OR_features_h_10.csv',\n",
       " 'Offshore_WA_OR_features_h_11.csv',\n",
       " 'Offshore_WA_OR_features_h_12.csv',\n",
       " 'Offshore_WA_OR_features_h_13.csv',\n",
       " 'Offshore_WA_OR_features_h_14.csv',\n",
       " 'Offshore_WA_OR_features_h_15.csv',\n",
       " 'Offshore_WA_OR_features_h_16.csv',\n",
       " 'Offshore_WA_OR_features_h_17.csv',\n",
       " 'Offshore_WA_OR_features_h_18.csv',\n",
       " 'Offshore_WA_OR_features_h_19.csv',\n",
       " 'Offshore_WA_OR_features_h_20.csv',\n",
       " 'Offshore_WA_OR_features_h_21.csv',\n",
       " 'Offshore_WA_OR_features_h_22.csv',\n",
       " 'Offshore_WA_OR_features_h_23.csv',\n",
       " 'Offshore_WA_OR_features_h_24.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "files = [file for file in glob.glob('Offshore_WA_OR_features_*.csv')]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Paso 1: only one h-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Offshore_WA_OR_features_h_12.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h11 = files[11]\n",
    "h11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create directory for each horizont (each horizon is a regressor)\n",
    "#horizont = 12\n",
    "#directory_by_horizont = os.path.join(directory, \n",
    "#                                     'K-nearest-regressor',\n",
    "#                                     'model_saved_h={0:03d}'.format(horizont)\n",
    "#                                    )\n",
    "#if not os.path.exists(directory_by_horizont):\n",
    "#    os.makedirs(directory_by_horizont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>target_h12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01 17:00:00</th>\n",
       "      <td>6.96</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 18:00:00</th>\n",
       "      <td>5.28</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.19</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 19:00:00</th>\n",
       "      <td>5.32</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-01 20:00:00</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.16</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      f_0   f_1   f_2   f_3   f_4   f_5  target_h12\n",
       "target_date                                                        \n",
       "2004-01-01 17:00:00  6.96  5.28  5.32  4.93  4.05  3.95        6.11\n",
       "2004-01-01 18:00:00  5.28  5.32  4.93  4.05  3.95  4.19        6.42\n",
       "2004-01-01 19:00:00  5.32  4.93  4.05  3.95  4.19  4.89        5.74\n",
       "2004-01-01 20:00:00  4.93  4.05  3.95  4.19  4.89  5.16        4.52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file\n",
    "df_h11 = pd.read_csv(h11, delimiter=';', index_col=0)\n",
    "df_h11.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the best model for h=1\n",
    "\n",
    "# split the dataset in train, val and test\n",
    "data = dataframe_split(df_h11)\n",
    "train_set = data['train_set']\n",
    "validation_set = data['validation_set']\n",
    "test_set = data['test_set']\n",
    "\n",
    "\n",
    "# features and target columns\n",
    "features_columns = train_set.columns[1:-1]\n",
    "target_column = train_set.columns[-1:]\n",
    "\n",
    "# select the values of features and target columns.\n",
    "features_train_set = train_set[features_columns]\n",
    "target_train_set = train_set[target_column]\n",
    "features_validation_set = validation_set[features_columns]\n",
    "target_validation_set = validation_set[target_column]\n",
    "features_test_set = test_set[features_columns]\n",
    "target_test_set = test_set[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features columns: Index(['f_1', 'f_2', 'f_3', 'f_4', 'f_5'], dtype='object')\n",
      "target column: Index(['target_h12'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('features columns: {0}'.format(features_columns))\n",
    "print('target column: {0}'.format(target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = features_train_set.values; y_train = target_train_set.values\n",
    "x_val = features_validation_set.values; y_val = target_validation_set.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p3tf1]",
   "language": "python",
   "name": "conda-env-p3tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
